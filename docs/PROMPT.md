# Prompt engineering guide
**References**: 
- https://www.promptingguide.ai/kr
- https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api
- https://community.openai.com/

## 목차 ##
- [LLM 설정](#LLM-설정)
- [Prompt 구성 요소](#prompt-구성-요소)
- [Zero-Shot Prompting](#zero-shot-prompting)
- [Few-Shot Prompting](#few-shot-prompting)
- [ Chain-of-Thought Prompting](#생각의-사슬-프롬프팅)
- [Self-Consitency](#self-consistency-prompting)
- [Generate knowledge prompting](#generate-knowledge-prompting)

## LLM 설정
**temperature** : 해당 값이 낮을 수록 가장 확률이 높은 토큰이 출력된다. temperature 수치를 증가 할 수록 결과는 다양하고 창조적인 결과를 출력한다. 따라서 factual response만을 원하는 서비스의 경우에는 낮은 temperature를 사용하는 것이 좀 더 사실적이고 간결한 응답을 얻을 수 있다. 

**Top P**: 해당 값을 낮출 수록 사실적이고 정확한 답변을 출력한다 (exact and factual answers). *temperature*와 *Top P* 둘 중에 하나의 값만 설정해서 사용하는 것이 일반적이다.

reference: https://www.promptingguide.ai/introduction/settings

## Prompt 구성 요소
- 지시: 모델에게 수행할 특정 작업 또는 지시 사항 전달
- 문맥: 모델이 더 낳은 답변을 위해 외부의 정보나 추가적인 context를 전달 할 수 있음
- 입력 데이터: 질문
- 출력 지시자: 출력 형식의 지정

아래의 예시는 지시와 문맥 그리고 질문 사항과 원하는 출력 형태를 명확하게 전달하는 프롬프트를 나타낸다.

```plain
다음 텍스트에서 장소의 이름을 추출해 줘.
원하는 형식:
장소: 콤마로 구분해서 표시

입력: "대전찍고 부산찍고 서울갔다 인천 도착해서 밥 먹고 다시 강원도 양양 가서 스키타고 경기도 시흥시에 있는 집으로 도착했다"
```
위의 사례에서 보듯이 입력 사항을 "" 등으로 명확하게 표시하는 것이 더 낳은 엔지니어링 기법이다.
```plain
Summarize the text below as a bullet point list of the most important points.

Text: """
{text input here}
"""
```

## Zero shot prompting
모델에 아무런 예제를 제공하지 않는 것을 제로샷 프롬프팅이라고 한다. 만약 제로샷이 제대로 동작하지 않는 경우에는 프롬프트에 데모나 예시를 제공하여 퓨샷으로 프롬프트를 사용하는 것이 좋다.

## Few shot prompting
퓨샷(few-shot) 프롬프트는 프롬프트에서 데모를 제공하여 모델이 더 나은 성능을 발휘하도록 유도하는 문맥 내 학습을 가능하게 하는 기술이다. 

```plain
정말 멋지네요! // 부정
이건 나쁘다! // 긍정
와우 그 영화 정말 멋졌어요! // 긍정
정말 끔찍한 쇼였어! //
```
```plain
긍정적: 이거 멋지다!
부정적: 이것은 나쁘다!
긍정적: 와우, 그 영화 정말 멋졌어요!
부정적: 정말 끔찍한 쇼였어!
```

하지만, 아래와 같이 복잡한 추론 작업을 처리할 때에는 퓨샷 방식에 한계가 발생한다.
```plain
이 집합 {4, 8, 9, 15, 12, 2, 1}에서 홀수의 합은 짝수입니다.
A: 답은 거짓입니다.

이 집합 {17, 10, 19, 4, 8, 12, 24}에서 홀수의 합은 짝수입니다.
A: 정답은 참입니다.

이 집합 {16, 11, 14, 4, 8, 13, 24}에서 홀수의 합은 짝수입니다.
A: 답은 참입니다.

이 집합 {17, 9, 10, 12, 13, 4, 2}에서 홀수의 합은 짝수입니다.
A: 답은 거짓입니다.

이 집합 {15, 32, 5, 13, 82, 7, 1}에서 홀수의 합은 짝수입니다.
A:
```

```plain
정답은 참입니다.
```
여러번 질문을 하면 정답을 맞추는 경우도 있고 틀린 답을 제시하는 경우도 있다. 즉, 퓨샷 방식에 한계가 있음을 보여준다. 이러한 유형의 추론 문제에 대해 신뢰할 수 있는 답변을 얻으려면 몇 번의 프롬프트만으로는 충분하지 않다. 따라서 최근에는 더 복잡한 산술, 상식, 상징적 추론 작업을 처리하기 위해 CoT 프롬프팅을 사용한다.

## 생각의 사슬 프롬프팅
CoT 프롬프트는 중간 추론 단계를 통해 복잡한 추론을 가능하게 한다.
```plain
집합 {4, 8, 9, 15, 12, 2, 1}에서 홀수를 모두 더하면 짝수야.
답변: 홀수(9, 15, 1)를 모두 더하면 25가 돼. 위의 명제는 거짓이야.

집합 {17, 10, 19, 4, 8, 12, 24}에서 홀수를 모두 더하면 짝수야.
답변: 홀수(17, 19)를 모두 더하면 36이 돼. 위의 명제는 참이야.

집합 {16, 11, 14, 4, 8, 13, 24}에서 홀수를 모두 더하면 짝수야.
답변: 홀수(11, 13)를 모두 더하면 24가 돼. 위의 명제는 참이야.

집합 {17, 9, 10, 12, 13, 4, 2}에서 홀수를 모두 더하면 짝수야.
답변: 홀수(17, 9, 13)를 모두 더하면 39가 돼. 위의 명제는 거짓이야.

집합 {15, 32, 5, 13, 82, 7, 1}에서 홀수를 모두 더하면 짝수야.
답변:
```

```plain
홀수(15, 5, 13, 7, 1)를 모두 더하면 41이 됩니다. 따라서 위의 명제는 거짓입니다.
```
또한, zero-shot CoT를 통해 단계별로 (step by step) 생각해서 답변해 달라고 요청할 수도 있다. ("let's think step by step" prompt)

```plain
나는 시장에 가서 사과 10개를 샀어. 나는 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 사과가 몇 개나 남았니?

단계별로 생각해 보자.
```

```plain
처음에 사과 10개를 샀다.
이웃에게 2개를 주었으므로, 10 - 2 = 8개가 남았다.
수리공에게 2개를 주었으므로, 8 - 2 = 6개가 남았다.
추가로 사과 5개를 더 샀다. 따라서 6 + 5 = 11개가 된다.
마지막으로 1개를 먹었으므로, 11 - 1 = 10개가 남았다.
따라서, 사과는 10개가 남았습니다.
```
GPT가 단계별로 문제를 풀어 나가면서 답변하는 것을 확인할 수 있다.

## Self consistency prompting
CoT prompting의 진보된 기법으로 모델에게 여러 가지 few-shot 예제를 전달하여 더 복잡한 추론 과정을 참고하여 일관성 있게 답변할 수 있도록 한다. 

```plain
Q: 과수원에는 15그루의 나무가 있어. 과수원의 일꾼들이 오늘 과수원에 나무를 심을 거야. 나무 심기가 끝나면
21그루의 나무가 있을 거야. 오늘 과수원 일꾼들은 몇 그루의 나무를 심었을까?
A: 15그루로 시작합니다. 나중에 나무가 21그루가 됩니다. 그 차이가 그들이 심은 나무의 수일 것입니다.
따라서 그들은 21 - 15 = 6그루의 나무를 심었어야 합니다. 정답은 6입니다.

Q: 주차장에 3대의 차량이 있고 2대의 차량이 더 도착하면 주차장에 몇 대의 차량이 있을까?
A: 주차장에 이미 3대의 차량이 있습니다. 2대가 더 도착합니다. 이제 3 + 2 = 5대의 차량이 있습니다. 정답은 5입니다.

Q: 지호는 초콜릿을 32개, 여동생은 42개를 가지고 있었어. 둘이 35개를 먹었다면 총 몇 개가 남았을까?
A: 레아는 초콜릿 32개, 레아의 여동생은 42개를 가지고 있었습니다. 즉, 원래 32개 + 42개 = 74개의
초콜릿이 있었습니다. 35개를 먹었습니다. 따라서 총 74 - 35 = 39개의 초콜릿이 남아 있습니다. 정답은 39입니다.

Q: 선우는 막대 사탕을 20개 가지고 있었어. 그는 두리에게 막대 사탕을 몇 개 주었어. 이제 선우는 막대사탕 12개를 가지고 있어. 선우는 두리에게
몇 개의 막대 사탕을 줬을까?
A: 선우는 막대 사탕 20개를 가지고 있었습니다. 이제 선우는 12개만 가지고 있으므로, 나머지는 두리에게 주었을 것입니다. 선우가 두리에게 준 막대사탕의
20 - 12 = 8개의 막대 사탕을 두리에게 주었어야 합니다. 정답은 8개입니다.

Q: 도현이는 장난감이 다섯 개 있어. 크리스마스에 도현이는 엄마와 아빠로부터 각각 두 개의 장난감을 받았어. 도현이는 지금 몇 개의 장난감을
가지고 있을까?
A: 도현이의 장난감이 5개입니다. 엄마로부터 2개를 받았으므로 5 + 2 = 7개의 장난감을 가지고 있습니다. 그리고 아빠한테서 2개를 더 받았어요.
총 7 + 2 = 9 개의 장난감을 가지고 있습니다. 정답은 9입니다.

Q: 서버실에는 9대의 컴퓨터가 있었어. 월요일부터 목요일까지 각각 5대씩 컴퓨터가 더 설치되었어.
현재 서버실에는 몇 대의 컴퓨터가 있을까?
A: 월요일부터 목요일까지는 4일입니다. 매일 5대씩 컴퓨터가 추가되었습니다. 즉, 총 4 * 5 =
20대의 컴퓨터가 추가되었습니다. 처음에는 9대의 컴퓨터가 있었으므로 이제 9 + 20 = 29대의 컴퓨터가 있습니다.
정답은 29입니다.

Q: 수완이는 58개의 골프공을 가지고 있었어. 화요일에 그는 23개의 골프공을 잃어버렸어. 수요일에 2개를 더 잃어버렸어.
수요일이 끝났을 때 그가 가지고 있던 골프공은 몇 개였을까?
A: 수완이는 처음에 58개의 공을 가지고 있었습니다. 화요일에 23개를 잃어버렸으므로 그 이후에는 58 - 23 = 35개의 공을 가지고 있습니다.
수요일에 2개를 더 잃어버렸으므로 이제 35 - 2 = 33개의 공을 가지고 있습니다. 정답은 33입니다.

Q: 한얼이는 23달러를 가지고 있어. 그녀는 각각 3달러에 베이글 5개를 샀어. 한얼이에게 남은 돈은 얼마일까?
A: 한얼이는 각각 3달러에 베이글 5개를 샀습니다. 이것은 그녀가 5 * 3 = 15달러를 썼다는 것을 의미합니다.

Q: 나는 1000원을 가지고 있어. 한잔에  300원 짜리 커피 두 잔을 마시고 남은 돈의 반을 친구에게 빌려줬어. 그럼 내가 가진 돈은 얼마 남아 있을까?
A:
```

```plain
처음에는 1000원을 가지고 있습니다. 커피 두 잔을 사면 300원 * 2 = 600원이 소비됩니다. 남은 돈은 1000원 - 600원 = 400원입니다. 그리고 이 남은 돈의 반을 친구에게 빌려준다면, 400원 / 2 = 200원이 남게 됩니다. 따라서 남은 돈은 200원입니다.
```

## Generate knowledge prompting
모델에 질문에 앞서 질문과 관련된 지식을 생성하게 하고 그 지식을 프롬프트의 일부로 사용하여 질문에 답하게 하는 방식을 말한다. 아래와 같이 few shot learning을 통해 지식을 생성하게 한다.

```plain
Input: 그리스는 멕시코보다 크다.
Knowledge: 그리스는 약 131,957 제곱 킬로미터이고, 멕시코는 약 1,964,375 제곱 킬로미터로 멕시코가 그리스보다 1,389% 더 크다.

Input: 안경은 항상 김이 서린다.
Knowledge: 안경 렌즈에는 땀, 호흡 및 주변 습도에서 나오는 수증기가 차가운 표면에 닿아 식은 다음 작은 액체 방울로 변하여 안개처럼 보이는 막을 형성할 때 응결이 발생한다. 특히 외부 공기가 차가울 때는 호흡에 비해 렌즈가 상대적으로 차가워진다.

Input: 물고기는 생각할 수 있다.
Knowledge: 물고기는 보기보다 훨씬 더 똑똑하다. 기억력과 같은 많은 영역에서 물고기의 인지 능력은 인간이 아닌 영장류를 포함한 '고등' 척추동물과 비슷하거나 그 이상이다. 물고기의 장기 기억력은 복잡한 사회적 관계를 추적하는 데 도움이 된다.

Input: 평생 담배를 피우는 것의 일반적인 결과는 폐암에 걸릴 확률이 정상보다 높다는 것입니다.
Knowledge: 평생 동안 하루 평균 담배를 한 개비 미만으로 꾸준히 피운 사람은 비흡연자보다 폐암으로 사망할 위험이 9배 높았다. 하루에 한 개비에서 열 개비 사이의 담배를 피운 사람들은 폐암으로 사망할 위험이 비흡연자보다 거의 12배 높았다.

Input: 돌은 조약돌과 같은 크기다.
Knowledge: 조약돌은 퇴적학의 우든-웬트워스 척도에 따라 입자 크기가 4~64밀리미터인 암석 덩어리다. 조약돌은 일반적으로 과립(직경 2~4밀리미터)보다는 크고 자갈(직경 64~256밀리미터)보다는 작은 것으로 간주된다.

Input: 골프의 목적 중 하나는 다른 사람보다 더 높은 점수를 얻기 위해 노력하는 것이다.
Knowledge:
```
모델이 생성한 지식을 질문과 함께 전달하여 답변을 얻는다.

```plain
Question: 골프의 목적 중 하나는 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 것이다. 예, 아니오?

Knowledge: 골프의 목적은 최소의 스트로크로 한 세트의 홀을 플레이하는 것이다. 골프 한 라운드는 일반적으로 18홀로 구성된다. 표준 골프 코스에서는 각 홀을 라운드마다 한 번씩 플레이합니다. 각 스트로크는 1점으로 계산되며 총 스트로크 수를 사용하여 게임의 승자를 결정한다.

설명하고 답하십시오: 
```
